{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import pylab\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance\n",
       "0  Police find mass graves with at least '15 bodi...      712  unrelated\n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree\n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated\n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated\n",
       "4  Spider burrowed through tourist's stomach and ...     1923   disagree"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainBodies = pd.read_csv('fncData/train_bodies.csv')\n",
    "trainStances = pd.read_csv('fncData/train_stances.csv')\n",
    "trainStancesRandom = pd.read_csv('fncData/train_stances.random.csv')\n",
    "trainStances.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID    Stance\n",
       "0  Police find mass graves with at least '15 bodi...      712   discuss\n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158   discuss\n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137  disagree\n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  disagree\n",
       "4  Spider burrowed through tourist's stomach and ...     1923     agree"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainStancesRandom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "limit = len(trainStances)\n",
    "limit = 1000\n",
    "strip = True\n",
    "lowercase = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Stances (20/49972):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>unrelated</th>\n",
       "      <th>agree</th>\n",
       "      <th>disagree</th>\n",
       "      <th>discuss</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police find mass graves with at least bodies n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>danny boyle is directing the untitled film set...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hundreds of palestinians flee floods in gaza a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hundreds of palestinians were evacuated from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>christian bale passes on role of steve jobs ac...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>year old moscow resident was hospitalized with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hbo and apple in talks for month apple tv stre...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reuters a canadian soldier was shot at the can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spider burrowed through tourist s stomach and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fear not arachnophobes the story of bunbury s ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  unrelated  agree  \\\n",
       "0  police find mass graves with at least bodies n...          1      0   \n",
       "1  hundreds of palestinians flee floods in gaza a...          0      1   \n",
       "2  christian bale passes on role of steve jobs ac...          1      0   \n",
       "3  hbo and apple in talks for month apple tv stre...          1      0   \n",
       "4  spider burrowed through tourist s stomach and ...          0      0   \n",
       "\n",
       "   disagree  discuss                                               Body  \n",
       "0         0        0  danny boyle is directing the untitled film set...  \n",
       "1         0        0  hundreds of palestinians were evacuated from t...  \n",
       "2         0        0  year old moscow resident was hospitalized with...  \n",
       "3         0        0  reuters a canadian soldier was shot at the can...  \n",
       "4         1        0  fear not arachnophobes the story of bunbury s ...  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Train Stances (20/%s):\" % (len(trainStances))\n",
    "# trainStances.head(20)\n",
    "\n",
    "trainStances[\"unrelated\"] = trainStances[\"Stance\"].apply(lambda x: 1 if x == \"unrelated\" else 0)\n",
    "trainStances[\"agree\"] = trainStances[\"Stance\"].apply(lambda x: 1 if x == \"agree\" else 0)\n",
    "trainStances[\"disagree\"] = trainStances[\"Stance\"].apply(lambda x: 1 if x == \"disagree\" else 0)\n",
    "trainStances[\"discuss\"] = trainStances[\"Stance\"].apply(lambda x: 1 if x == \"discuss\" else 0)\n",
    "trainStances[\"Body\"] = [\"\"] * len(trainStances)\n",
    "for index, row in trainStances[0:limit].iterrows():\n",
    "    trainStances.loc[index, \"Body\"] = trainBodies[trainBodies['Body ID'] == row[\"Body ID\"]]['articleBody'].item()\n",
    "\n",
    "\n",
    "import re\n",
    "def preprocess(text, lowercase, strip):\n",
    "    text = text.lower() if lowercase else text\n",
    "    text = \" \".join(re.findall(\"[a-zA-Z]+\", text)) if strip else text\n",
    "    return text\n",
    "\n",
    "if strip or lowercase:\n",
    "    trainStances[\"Body\"]= trainStances[\"Body\"].apply(lambda x: preprocess(x,lowercase,strip))\n",
    "    trainStances[\"Headline\"]= trainStances[\"Headline\"].apply(lambda x: preprocess(x,lowercase,strip))\n",
    "    \n",
    "\n",
    "trainStances = trainStances.drop(\"Body ID\", 1)\n",
    "trainStances = trainStances.drop(\"Stance\", 1)\n",
    "    \n",
    "trainStances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Stances Random (20/49972)\n"
     ]
    }
   ],
   "source": [
    "print \"Train Stances Random (20/%s)\" % (len(trainStancesRandom))\n",
    "# trainStancesRandom.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>unrelated</th>\n",
       "      <th>agree</th>\n",
       "      <th>disagree</th>\n",
       "      <th>discuss</th>\n",
       "      <th>Body</th>\n",
       "      <th>Number Of Common Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police find mass graves with at least bodies n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>danny boyle is directing the untitled film set...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hundreds of palestinians flee floods in gaza a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hundreds of palestinians were evacuated from t...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>christian bale passes on role of steve jobs ac...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>year old moscow resident was hospitalized with...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hbo and apple in talks for month apple tv stre...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reuters a canadian soldier was shot at the can...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spider burrowed through tourist s stomach and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fear not arachnophobes the story of bunbury s ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  unrelated  agree  \\\n",
       "0  police find mass graves with at least bodies n...          1      0   \n",
       "1  hundreds of palestinians flee floods in gaza a...          0      1   \n",
       "2  christian bale passes on role of steve jobs ac...          1      0   \n",
       "3  hbo and apple in talks for month apple tv stre...          1      0   \n",
       "4  spider burrowed through tourist s stomach and ...          0      0   \n",
       "\n",
       "   disagree  discuss                                               Body  \\\n",
       "0         0        0  danny boyle is directing the untitled film set...   \n",
       "1         0        0  hundreds of palestinians were evacuated from t...   \n",
       "2         0        0  year old moscow resident was hospitalized with...   \n",
       "3         0        0  reuters a canadian soldier was shot at the can...   \n",
       "4         1        0  fear not arachnophobes the story of bunbury s ...   \n",
       "\n",
       "   Number Of Common Words  \n",
       "0                       2  \n",
       "1                      10  \n",
       "2                       4  \n",
       "3                       2  \n",
       "4                       9  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build feature vocabulary\n",
    "ngram = 1\n",
    "vectorizer = CountVectorizer(ngram_range=(1, ngram))\n",
    "trainStances[\"Number Of Common Words\"] = [-1 for x in range(len(trainStances))]\n",
    "trainStances[\"Number Of Words In Body\"] = [-1 for x in range(len(trainStances))]\n",
    "\n",
    "for index, row in trainStances[0:limit].iterrows():\n",
    "    headline = row['Headline']\n",
    "    body = row['Body']\n",
    "    \n",
    "#     print index\n",
    "#     print \"HEADLINE: \\n%s\\n\" % headline\n",
    "#     print \"BODY: \\n%s\\n\" % body\n",
    "\n",
    "    headline_words = headline.split()\n",
    "    body_words = body.split()\n",
    "    \n",
    "    num_words_in_common = len(set(headline_words).intersection(body_words))\n",
    "    \n",
    "    trainStances.loc[index, \"Number Of Common Words\"] = num_words_in_common  \n",
    "    trainStances.loc[index, \"Number Of Words In Body\"] = len(body_words) \n",
    "\n",
    "trainStances.head()\n",
    "\n",
    "# I'd like to graph the num_words_in_common integer to the stance classification, to see what kind of correlation we're working with here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unrelated</th>\n",
       "      <th>agree</th>\n",
       "      <th>disagree</th>\n",
       "      <th>discuss</th>\n",
       "      <th>Number Of Common Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unrelated</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.495683</td>\n",
       "      <td>-0.207277</td>\n",
       "      <td>-0.738470</td>\n",
       "      <td>-0.666706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agree</th>\n",
       "      <td>-0.495683</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.041357</td>\n",
       "      <td>-0.147343</td>\n",
       "      <td>0.342553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disagree</th>\n",
       "      <td>-0.207277</td>\n",
       "      <td>-0.041357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.061614</td>\n",
       "      <td>0.115451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discuss</th>\n",
       "      <td>-0.738470</td>\n",
       "      <td>-0.147343</td>\n",
       "      <td>-0.061614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.490998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number Of Common Words</th>\n",
       "      <td>-0.666706</td>\n",
       "      <td>0.342553</td>\n",
       "      <td>0.115451</td>\n",
       "      <td>0.490998</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        unrelated     agree  disagree   discuss  \\\n",
       "unrelated                1.000000 -0.495683 -0.207277 -0.738470   \n",
       "agree                   -0.495683  1.000000 -0.041357 -0.147343   \n",
       "disagree                -0.207277 -0.041357  1.000000 -0.061614   \n",
       "discuss                 -0.738470 -0.147343 -0.061614  1.000000   \n",
       "Number Of Common Words  -0.666706  0.342553  0.115451  0.490998   \n",
       "\n",
       "                        Number Of Common Words  \n",
       "unrelated                            -0.666706  \n",
       "agree                                 0.342553  \n",
       "disagree                              0.115451  \n",
       "discuss                               0.490998  \n",
       "Number Of Common Words                1.000000  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainStances[0:limit].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "categoryNumberOfCommonWordsMeans = {\n",
    "    \"unrelated\":0, \"discuss\":0, \"agree\":0, \"disagree\":0\n",
    "}\n",
    "for category in categoryNumberOfCommonWordsMeans: #for each category calculate the mean number of words in common between header and body \n",
    "    categoryNumberOfCommonWordsMeans[category] = trainStances[0:limit][trainStances[category] == 1].mean()[\"Number Of Common Words\"]\n",
    "\n",
    "print(categoryNumberOfCommonWordsMeans)\n",
    "\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "d = categoryNumberOfCommonWordsMeans\n",
    "X = np.arange(len(d))\n",
    "pl.bar(X, d.values(), align='center', width=0.5)\n",
    "pl.xticks(X, d.keys())\n",
    "ymax = max(d.values()) + 1\n",
    "pl.ylim(0, ymax)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Size:', (1000, 15064), 'same')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bodies = [x for x in trainStances[0:limit][\"Body\"]]\n",
    "headlines = [x for x in trainStances[0:limit][\"Headline\"]]\n",
    "\n",
    "# could make count vectors for each type\n",
    "cv=CountVectorizer()\n",
    "# or tfidf vectorizer \n",
    "#cv=TfidfVectorizer()\n",
    "cv.fit(bodies + headlines)\n",
    "bodyBOWVectors = cv.transform(bodies)\n",
    "headlineBOWVectors = cv.transform(headlines)\n",
    "\n",
    "print(\"Size:\", headlineBOWVectors.shape, \"same\" if bodyBOWVectors.shape==headlineBOWVectors.shape else \"DIFFERENT!!!\")\n",
    "\n",
    "# maybe its better to have one vector where the presence of the word is scaled\n",
    "# up if that word is present in the headline, otherwise scaled down \n",
    "# something of the form, but scaled with constants...\n",
    "combinedVectors = bodyBOWVectors.multiply(headlineBOWVectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import scipy.sparse as sp\n",
    "\n",
    "lr = LinearRegression()\n",
    "x_train = sp.csr_matrix([[x] for x in trainStances[0:limit][\"Number Of Common Words\"]])\n",
    "y_train = sp.csr_matrix([[x] for x in trainStances[0:limit][\"unrelated\"]])\n",
    "print(x_train.shape, type(x_train))\n",
    "print(y_train.shape, type(y_train))\n",
    "lr.fit(x_train, y_train)\n",
    "# scores = cross_val_score(lr, x_train, y_train, cv=5)\n",
    "accuracy = scores.mean()\n",
    "print \"Crossvalidation\", scores, (\"Accuracy: %0.2f (+/- %0.2f)\" % (accuracy, scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-d9c2ad8e2831>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    517\u001b[0m         X, y, X_offset, y_offset, X_scale = self._preprocess_data(\n\u001b[1;32m    518\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             copy=self.copy_X, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(X, y, fit_intercept, normalize, copy, sample_weight, return_mean)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mX_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0my_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0mscl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mrcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Make this warning show up first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mitems\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "predictions = lr.predict(x_test)\n",
    "\n",
    "o = DictWriter(open(\"predictions.csv\", 'w'), [\"Id\", \"spoiler\"])\n",
    "o.writeheader()\n",
    "for ii, pp in zip([x['Id'] for x in test], predictions):\n",
    "    d = {'Id': ii, 'spoiler': labels[pp]}\n",
    "    o.writerow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1      10\n",
       "2       4\n",
       "3       2\n",
       "4       9\n",
       "5      16\n",
       "6       2\n",
       "7       2\n",
       "8       8\n",
       "9       4\n",
       "10      0\n",
       "11     11\n",
       "12      2\n",
       "13      3\n",
       "14      8\n",
       "15      9\n",
       "16      5\n",
       "17      6\n",
       "18      4\n",
       "19      2\n",
       "20      2\n",
       "21      8\n",
       "22      3\n",
       "23      6\n",
       "24      6\n",
       "25     10\n",
       "26      1\n",
       "27      0\n",
       "28      3\n",
       "29      6\n",
       "       ..\n",
       "970     5\n",
       "971     4\n",
       "972     1\n",
       "973     1\n",
       "974     3\n",
       "975     3\n",
       "976     0\n",
       "977     9\n",
       "978     6\n",
       "979     1\n",
       "980     1\n",
       "981     2\n",
       "982    13\n",
       "983    12\n",
       "984     3\n",
       "985     8\n",
       "986     4\n",
       "987     2\n",
       "988     4\n",
       "989     4\n",
       "990     1\n",
       "991     4\n",
       "992     2\n",
       "993    11\n",
       "994     2\n",
       "995     5\n",
       "996     8\n",
       "997     5\n",
       "998     0\n",
       "999    13\n",
       "Name: Number Of Common Words, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainStances[0:limit][\"Number Of Common Words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
