{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name LinearRegression",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-8ea2c3c0b911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name LinearRegression"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import pylab\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Bodies (20/1683):\n"
     ]
    }
   ],
   "source": [
    "trainBodies = pd.read_csv('fncData/train_bodies.csv')\n",
    "trainStances = pd.read_csv('fncData/train_stances.csv')\n",
    "trainStancesRandom = pd.read_csv('fncData/train_stances.random.csv')\n",
    "\n",
    "print \"Train Bodies (20/%s):\" % (len(trainBodies))\n",
    "#print trainBodies.head(20)\n",
    "\n",
    "# to get articleBody:\n",
    "# trainBodies.get_value(0, 'articleBody')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit = len(trainStances)\n",
    "limit = 1000\n",
    "strip = True\n",
    "lowercase = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Stances (20/49972):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>unrelated</th>\n",
       "      <th>agree</th>\n",
       "      <th>disagree</th>\n",
       "      <th>discuss</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police find mass graves with at least bodies n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>danny boyle is directing the untitled film set...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hundreds of palestinians flee floods in gaza a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hundreds of palestinians were evacuated from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>christian bale passes on role of steve jobs ac...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>year old moscow resident was hospitalized with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hbo and apple in talks for month apple tv stre...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reuters a canadian soldier was shot at the can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spider burrowed through tourist s stomach and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fear not arachnophobes the story of bunbury s ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  unrelated  agree  \\\n",
       "0  police find mass graves with at least bodies n...          1      0   \n",
       "1  hundreds of palestinians flee floods in gaza a...          0      1   \n",
       "2  christian bale passes on role of steve jobs ac...          1      0   \n",
       "3  hbo and apple in talks for month apple tv stre...          1      0   \n",
       "4  spider burrowed through tourist s stomach and ...          0      0   \n",
       "\n",
       "   disagree  discuss                                               Body  \n",
       "0         0        0  danny boyle is directing the untitled film set...  \n",
       "1         0        0  hundreds of palestinians were evacuated from t...  \n",
       "2         0        0  year old moscow resident was hospitalized with...  \n",
       "3         0        0  reuters a canadian soldier was shot at the can...  \n",
       "4         1        0  fear not arachnophobes the story of bunbury s ...  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Train Stances (20/%s):\" % (len(trainStances))\n",
    "# trainStances.head(20)\n",
    "\n",
    "trainStances[\"unrelated\"] = trainStances[\"Stance\"].apply(lambda x: 1 if x == \"unrelated\" else 0)\n",
    "trainStances[\"agree\"] = trainStances[\"Stance\"].apply(lambda x: 1 if x == \"agree\" else 0)\n",
    "trainStances[\"disagree\"] = trainStances[\"Stance\"].apply(lambda x: 1 if x == \"disagree\" else 0)\n",
    "trainStances[\"discuss\"] = trainStances[\"Stance\"].apply(lambda x: 1 if x == \"discuss\" else 0)\n",
    "trainStances[\"Body\"] = [\"\"] * len(trainStances)\n",
    "for index, row in trainStances[0:limit].iterrows():\n",
    "    trainStances.loc[index, \"Body\"] = trainBodies[trainBodies['Body ID'] == row[\"Body ID\"]]['articleBody'].item()\n",
    "\n",
    "\n",
    "import re\n",
    "def preprocess(text, lowercase, strip):\n",
    "    text = text.lower() if lowercase else text\n",
    "    text = \" \".join(re.findall(\"[a-zA-Z]+\", text)) if strip else text\n",
    "    return text\n",
    "\n",
    "if strip or lowercase:\n",
    "    trainStances[\"Body\"]= trainStances[\"Body\"].apply(lambda x: preprocess(x,lowercase,strip))\n",
    "    trainStances[\"Headline\"]= trainStances[\"Headline\"].apply(lambda x: preprocess(x,lowercase,strip))\n",
    "    \n",
    "\n",
    "trainStances = trainStances.drop(\"Body ID\", 1)\n",
    "trainStances = trainStances.drop(\"Stance\", 1)\n",
    "    \n",
    "trainStances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Stances Random (20/49972)\n"
     ]
    }
   ],
   "source": [
    "print \"Train Stances Random (20/%s)\" % (len(trainStancesRandom))\n",
    "# trainStancesRandom.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>unrelated</th>\n",
       "      <th>agree</th>\n",
       "      <th>disagree</th>\n",
       "      <th>discuss</th>\n",
       "      <th>Body</th>\n",
       "      <th>Number Of Common Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police find mass graves with at least bodies n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>danny boyle is directing the untitled film set...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hundreds of palestinians flee floods in gaza a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hundreds of palestinians were evacuated from t...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>christian bale passes on role of steve jobs ac...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>year old moscow resident was hospitalized with...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hbo and apple in talks for month apple tv stre...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reuters a canadian soldier was shot at the can...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spider burrowed through tourist s stomach and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fear not arachnophobes the story of bunbury s ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  unrelated  agree  \\\n",
       "0  police find mass graves with at least bodies n...          1      0   \n",
       "1  hundreds of palestinians flee floods in gaza a...          0      1   \n",
       "2  christian bale passes on role of steve jobs ac...          1      0   \n",
       "3  hbo and apple in talks for month apple tv stre...          1      0   \n",
       "4  spider burrowed through tourist s stomach and ...          0      0   \n",
       "\n",
       "   disagree  discuss                                               Body  \\\n",
       "0         0        0  danny boyle is directing the untitled film set...   \n",
       "1         0        0  hundreds of palestinians were evacuated from t...   \n",
       "2         0        0  year old moscow resident was hospitalized with...   \n",
       "3         0        0  reuters a canadian soldier was shot at the can...   \n",
       "4         1        0  fear not arachnophobes the story of bunbury s ...   \n",
       "\n",
       "   Number Of Common Words  \n",
       "0                       2  \n",
       "1                      10  \n",
       "2                       4  \n",
       "3                       2  \n",
       "4                       9  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build feature vocabulary\n",
    "ngram = 1\n",
    "vectorizer = CountVectorizer(ngram_range=(1, ngram))\n",
    "trainStances[\"Number Of Common Words\"] = [-1 for x in range(len(trainStances))]\n",
    "\n",
    "for index, row in trainStances[0:limit].iterrows():\n",
    "    headline = row['Headline']\n",
    "    body = row['Body']\n",
    "    \n",
    "#     print index\n",
    "#     print \"HEADLINE: \\n%s\\n\" % headline\n",
    "#     print \"BODY: \\n%s\\n\" % body\n",
    "\n",
    "    headline_words = headline.split()\n",
    "    body_words = body.split()\n",
    "    \n",
    "    num_words_in_common = len(set(headline_words).intersection(body_words))\n",
    "    \n",
    "    trainStances.loc[index, \"Number Of Common Words\"] = num_words_in_common \n",
    "\n",
    "trainStances.head()\n",
    "\n",
    "# I'd like to graph the num_words_in_common integer to the stance classification, to see what kind of correlation we're working with here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unrelated</th>\n",
       "      <th>agree</th>\n",
       "      <th>disagree</th>\n",
       "      <th>discuss</th>\n",
       "      <th>Number Of Common Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unrelated</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.495683</td>\n",
       "      <td>-0.207277</td>\n",
       "      <td>-0.738470</td>\n",
       "      <td>-0.666706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agree</th>\n",
       "      <td>-0.495683</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.041357</td>\n",
       "      <td>-0.147343</td>\n",
       "      <td>0.342553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disagree</th>\n",
       "      <td>-0.207277</td>\n",
       "      <td>-0.041357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.061614</td>\n",
       "      <td>0.115451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discuss</th>\n",
       "      <td>-0.738470</td>\n",
       "      <td>-0.147343</td>\n",
       "      <td>-0.061614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.490998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number Of Common Words</th>\n",
       "      <td>-0.666706</td>\n",
       "      <td>0.342553</td>\n",
       "      <td>0.115451</td>\n",
       "      <td>0.490998</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        unrelated     agree  disagree   discuss  \\\n",
       "unrelated                1.000000 -0.495683 -0.207277 -0.738470   \n",
       "agree                   -0.495683  1.000000 -0.041357 -0.147343   \n",
       "disagree                -0.207277 -0.041357  1.000000 -0.061614   \n",
       "discuss                 -0.738470 -0.147343 -0.061614  1.000000   \n",
       "Number Of Common Words  -0.666706  0.342553  0.115451  0.490998   \n",
       "\n",
       "                        Number Of Common Words  \n",
       "unrelated                            -0.666706  \n",
       "agree                                 0.342553  \n",
       "disagree                              0.115451  \n",
       "discuss                               0.490998  \n",
       "Number Of Common Words                1.000000  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainStances[0:limit].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unrelated': 2.6227208976157081, 'disagree': 7.0, 'discuss': 7.572222222222222, 'agree': 7.7111111111111112}\n"
     ]
    }
   ],
   "source": [
    "categoryNumberOfCommonWordsMeans = {\n",
    "    \"unrelated\":0, \"discuss\":0, \"agree\":0, \"disagree\":0\n",
    "}\n",
    "for category in categoryNumberOfCommonWordsMeans: #for each category calculate the mean number of words in common between header and body \n",
    "    categoryNumberOfCommonWordsMeans[category] = trainStances[0:limit][trainStances[category] == 1].mean()[\"Number Of Common Words\"]\n",
    "\n",
    "print(categoryNumberOfCommonWordsMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bodies = [x for x in trainStances[0:limit][\"Body\"]]\n",
    "headlines = [x for x in trainStances[0:limit][\"Headline\"]]\n",
    "\n",
    "# could make count vectors for each type\n",
    "bodyBOWVectors = CountVectorizer(analyzer=\"word\").fit_transform(bodies)\n",
    "headlineBOWVectors = CountVectorizer(analyzer=\"word\").fit_transform(headlines)\n",
    "\n",
    "# maybe its also OK to have one vectorizer where the presence of the word is scaled up if that word is present in the headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
